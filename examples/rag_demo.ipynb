{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read wiki data\n",
      "0 torch.Size([1, 300])\n",
      "1 torch.Size([1000000, 300])\n",
      "1000001 torch.Size([1000000, 300])\n",
      "2000001 torch.Size([994923, 300])\n",
      "2994924 torch.Size([1, 300])\n",
      "2994925 torch.Size([1000000, 300])\n",
      "3994925 torch.Size([1000000, 300])\n",
      "4994925 torch.Size([994922, 300])\n",
      "5989847 torch.Size([1, 300])\n",
      "5989848 torch.Size([1000000, 300])\n",
      "6989848 torch.Size([1000000, 300])\n",
      "7989848 torch.Size([1000000, 300])\n",
      "8989848 torch.Size([1000000, 300])\n",
      "9989848 torch.Size([1000000, 300])\n",
      "10989848 torch.Size([1000000, 300])\n",
      "11989848 torch.Size([1000000, 300])\n",
      "12989848 torch.Size([1000000, 300])\n",
      "13989848 torch.Size([1000000, 300])\n",
      "14989848 torch.Size([1000000, 300])\n",
      "15989848 torch.Size([1000000, 300])\n",
      "16989848 torch.Size([797125, 300])\n",
      "17786973 torch.Size([1, 300])\n",
      "17786974 torch.Size([1000000, 300])\n",
      "18786974 torch.Size([1000000, 300])\n",
      "19786974 torch.Size([1000000, 300])\n",
      "20786974 torch.Size([1000000, 300])\n",
      "21786974 torch.Size([1000000, 300])\n",
      "22786974 torch.Size([1000000, 300])\n",
      "23786974 torch.Size([1000000, 300])\n",
      "24786974 torch.Size([1000000, 300])\n",
      "25786974 torch.Size([1000000, 300])\n",
      "26786974 torch.Size([1000000, 300])\n",
      "27786974 torch.Size([1000000, 300])\n",
      "28786974 torch.Size([536327, 300])\n",
      "read embeddings into graph\n",
      "constructed graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54276/2569880275.py:147: UserWarning: Word2Vec encoder is for testing/debugging purposes only!\n",
      "  warnings.warn(\"Word2Vec encoder is for testing/debugging purposes only!\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys, os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import rmm\n",
    "from rmm.allocators.torch import rmm_torch_allocator\n",
    "from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "\n",
    "# Initialize shared allocator to prevent fragmentation\n",
    "rmm.reinitialize(devices=0, pool_allocator=False, managed_memory=False)\n",
    "\n",
    "import cupy\n",
    "cupy.cuda.set_allocator(rmm_cupy_allocator)\n",
    "\n",
    "import torch\n",
    "torch.cuda.change_current_allocator(rmm_torch_allocator)\n",
    "\n",
    "import cudf\n",
    "\n",
    "sys.path.append('/mnt/bitgraph')\n",
    "sys.path.append('/mnt/gremlin++')\n",
    "from pybitgraph import BitGraph\n",
    "\n",
    "from preprocess import Sentence_Transformer, Word2Vec_Transformer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def read_wiki_data(fname, skip_empty=True):\n",
    "    df = cudf.read_json('/mnt/para_with_hyperlink.jsonl', lines=True)\n",
    "\n",
    "    mentions = df.mentions.explode()\n",
    "    mentions = mentions[~mentions.struct.field('sent_idx').isna()]\n",
    "    mentions = mentions[~mentions.struct.field('ref_ids').isna()]\n",
    "\n",
    "    df['sentence_offsets'] = cupy.concatenate([\n",
    "        cupy.array([0]),\n",
    "        df.sentences.list.len().cumsum().values[:-1]\n",
    "    ])\n",
    "\n",
    "    destinations_m = mentions.struct.field('ref_ids').list.get(0).astype('int64').values\n",
    "    sources_m = mentions.struct.field('sent_idx').values + df.sentence_offsets[mentions.index].values + len(df)\n",
    "\n",
    "    if skip_empty:\n",
    "        # Does not add vertices/edges for vertices with no embedding\n",
    "        f = destinations_m < len(df)\n",
    "        destinations_m = destinations_m[f]\n",
    "        sources_m = sources_m[f]\n",
    "        del f\n",
    "\n",
    "    eim = torch.stack([\n",
    "        torch.as_tensor(sources_m, device='cuda'),\n",
    "        torch.as_tensor(destinations_m, device='cuda'),\n",
    "    ])\n",
    "\n",
    "    sentences = df.sentences.explode().reset_index().rename({\"index\": 'article'},axis=1)\n",
    "\n",
    "    sources_s = sentences.index.values + len(df)\n",
    "    destinations_s = sentences.article.values\n",
    "    eis = torch.stack([\n",
    "        torch.as_tensor(sources_s, device='cuda'),\n",
    "        torch.as_tensor(destinations_s, device='cuda'),\n",
    "    ])\n",
    "\n",
    "    eix = torch.concatenate([eim,eis],axis=1)\n",
    "    del eis\n",
    "    del eim\n",
    "\n",
    "    return eix, df.title.to_pandas(), sentences.sentences.to_pandas()\n",
    "\n",
    "\n",
    "def read_embeddings(graph, directory, td):\n",
    "    ex = re.compile(r'part_([0-9]+)\\_([0-9]+).pt')\n",
    "    def fname_to_key(s):\n",
    "        m = ex.match(s)\n",
    "        return int(m[1]), int(m[2])\n",
    "\n",
    "    ix = 0\n",
    "\n",
    "    for emb_type in ['titles', 'sentences']:\n",
    "        path = os.path.join(directory, emb_type)\n",
    "        files = os.listdir(path)\n",
    "\n",
    "        files = sorted(files, key=fname_to_key)\n",
    "        for f in files:\n",
    "            e = torch.load(os.path.join(path, f), weights_only=True, map_location='cuda').reshape((-1, td))\n",
    "\n",
    "            print(ix, e.shape)\n",
    "            graph.set_vertex_embeddings('emb', ix, ix + e.shape[0] - 1, e)\n",
    "            \n",
    "            ix += e.shape[0]\n",
    "            del e\n",
    "\n",
    "\n",
    "def getem_roberta(model, tokenizer, text):\n",
    "    t = tokenizer(text, return_tensors='pt')\n",
    "    while t.input_ids.shape[1] > 512:\n",
    "        a = a[:-10]\n",
    "        t = tokenizer(a, return_tensors='pt')\n",
    "    return model(t.input_ids, t.attention_mask)\n",
    "\n",
    "\n",
    "def getem_w2v(model, text):\n",
    "    return model(text)\n",
    "\n",
    "\n",
    "args = {\n",
    "    'skip_empty_vertices': True,\n",
    "    'property_storage': 'managed',\n",
    "    'fname': '/mnt/para_with_hyperlink.jsonl',\n",
    "    'embeddings_dir': '/mnt/bitgraph/data/rag/w2v/',\n",
    "    'embedding_type': 'w2v',\n",
    "    'w2v_path': '/mnt/GoogleNews-vectors-negative300.bin.gz',\n",
    "}\n",
    "\n",
    "eix, titles, sentences = read_wiki_data(\n",
    "    args['fname'],\n",
    "    args['skip_empty_vertices']\n",
    ")\n",
    "print('read wiki data')\n",
    "\n",
    "graph = BitGraph(\n",
    "    'int64',\n",
    "    'int64',\n",
    "    'DEVICE',\n",
    "    'DEVICE',\n",
    "    args['property_storage'].upper(),\n",
    ")\n",
    "\n",
    "graph.add_vertices(eix.max() + 1)\n",
    "graph.add_edges(eix[0], eix[1], 'link')\n",
    "\n",
    "read_embeddings(\n",
    "    graph,\n",
    "    args['embeddings_dir'],\n",
    "    td=300 if args['embedding_type'] == 'w2v' else 1024,\n",
    ")    \n",
    "print('read embeddings into graph')\n",
    "\n",
    "g = graph.traversal()\n",
    "print('constructed graph')\n",
    "\n",
    "if args['embedding_type'] == 'w2v':\n",
    "    import gensim\n",
    "    warnings.warn(\"Word2Vec encoder is for testing/debugging purposes only!\")\n",
    "    module = Word2Vec_Transformer(\n",
    "        gensim.models.KeyedVectors.load_word2vec_format(args['w2v_path'], binary=True),\n",
    "        dim=300,\n",
    "    )\n",
    "    getem = lambda t : getem_w2v(module, t)\n",
    "elif args['embedding_type'] == 'roberta':\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/all-roberta-large-v1')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-roberta-large-v1')\n",
    "    \n",
    "    mod = Sentence_Transformer(model).cuda()\n",
    "    import torch._dynamo\n",
    "    torch._dynamo.reset()\n",
    "\n",
    "    module = torch.compile(mod, fullgraph=True)\n",
    "    getem = lambda t : getem_roberta(module, tokenizer, t)\n",
    "else:\n",
    "    raise ValueError(\"Expected 'w2v' or 'roberta' for embedding type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(search_query, lim=4):\n",
    "    qe = getem(search_query)\n",
    "    vids = g.V().like('emb', [qe], lim).toArray()\n",
    "\n",
    "    f = vids < len(titles)\n",
    "    article_ids = vids[f]\n",
    "    sentence_ids = vids[~f] - len(titles)\n",
    "\n",
    "    print('articles:', titles.iloc[article_ids.get()])\n",
    "    print('sentences:', sentences.iloc[sentence_ids.get()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>evidences</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13f5ad2c088c11ebbd6fac1f6bf848b6</td>\n",
       "      <td>bridge_comparison</td>\n",
       "      <td>Are director of film Move (1970 Film) and dire...</td>\n",
       "      <td>[[Stuart Rosenberg, [Stuart Rosenberg (August ...</td>\n",
       "      <td>[[Move (1970 film), 0], [Méditerranée (1963 fi...</td>\n",
       "      <td>[[Move (1970 film), director, Stuart Rosenberg...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3057c6c4086111ebbd5dac1f6bf848b6</td>\n",
       "      <td>bridge_comparison</td>\n",
       "      <td>Do both films The Falcon (Film) and Valentin T...</td>\n",
       "      <td>[[The Falcon Takes Over, [The Falcon Takes Ove...</td>\n",
       "      <td>[[The Falcon (film), 0], [Valentin the Good, 0...</td>\n",
       "      <td>[[The Falcon (film), director, Vatroslav Mimic...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89bc944808a111ebbd79ac1f6bf848b6</td>\n",
       "      <td>bridge_comparison</td>\n",
       "      <td>Which film whose director is younger, Charge I...</td>\n",
       "      <td>[[Danger: Diabolik, [Danger:, Diabolik  is a 1...</td>\n",
       "      <td>[[Charge It to Me, 1], [Danger: Diabolik, 1], ...</td>\n",
       "      <td>[[Charge It to Me, director, Roy William Neill...</td>\n",
       "      <td>Danger: Diabolik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633f80660bdd11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What is the date of birth of Mina Gerhardsen's...</td>\n",
       "      <td>[[Pamela Jain, [Pamela Jain is an Indian playb...</td>\n",
       "      <td>[[Mina Gerhardsen, 1], [Rune Gerhardsen, 0]]</td>\n",
       "      <td>[[Mina Gerhardsen, father, Rune Gerhardsen], [...</td>\n",
       "      <td>13 June 1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2dc3f9740bda11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What nationality is the director of film Weddi...</td>\n",
       "      <td>[[Weekend in Paradise (1931 film), [Weekend in...</td>\n",
       "      <td>[[Wedding Night in Paradise (1950 film), 0], [...</td>\n",
       "      <td>[[Wedding Night in Paradise, director, Géza vo...</td>\n",
       "      <td>Hungarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167449</th>\n",
       "      <td>56100d300bdc11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What is the place of birth of the director of ...</td>\n",
       "      <td>[[S. N. Mathur, [S.N. Mathur was the Director ...</td>\n",
       "      <td>[[Rolling in Money, 0], [Albert Parker (direct...</td>\n",
       "      <td>[[Rolling in Money, director, Albert Parker], ...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167450</th>\n",
       "      <td>3df1a97108ad11ebbd83ac1f6bf848b6</td>\n",
       "      <td>comparison</td>\n",
       "      <td>Who was born first, Dušan Ninić or Eszter Balint?</td>\n",
       "      <td>[[Tom Dickinson, [Thomas Eastwood Dickinson( 1...</td>\n",
       "      <td>[[Dušan Ninić, 0], [Eszter Balint, 0]]</td>\n",
       "      <td>[[Dušan Ninić, date of birth, September 6, 195...</td>\n",
       "      <td>Dušan Ninić</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167451</th>\n",
       "      <td>8be4ef3e0bdc11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>When did the director of film Morchha die?</td>\n",
       "      <td>[[Thomas Scott (diver), [Thomas Scott( 1907- d...</td>\n",
       "      <td>[[Morchha, 0], [Ravikant Nagaich, 0]]</td>\n",
       "      <td>[[Morchha, director, Ravikant Nagaich], [Ravik...</td>\n",
       "      <td>6 January 1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167452</th>\n",
       "      <td>12357df20bdc11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What is the date of birth of the director of f...</td>\n",
       "      <td>[[Peter Levin, [Peter Levin is an American dir...</td>\n",
       "      <td>[[Double Cross (1951 film), 0], [Riccardo Fred...</td>\n",
       "      <td>[[Double Cross, director, Riccardo Freda], [Ri...</td>\n",
       "      <td>24 February 1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167453</th>\n",
       "      <td>613fb15e0bde11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>Where did the performer of song White Noise (L...</td>\n",
       "      <td>[[White Noise (Linkin Park song), [White Noise...</td>\n",
       "      <td>[[White Noise (Linkin Park song), 0], [Chester...</td>\n",
       "      <td>[[White Noise, performer, Chester Bennington],...</td>\n",
       "      <td>Palos Verdes Estates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167454 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     _id               type  \\\n",
       "0       13f5ad2c088c11ebbd6fac1f6bf848b6  bridge_comparison   \n",
       "1       3057c6c4086111ebbd5dac1f6bf848b6  bridge_comparison   \n",
       "2       89bc944808a111ebbd79ac1f6bf848b6  bridge_comparison   \n",
       "3       633f80660bdd11eba7f7acde48001122      compositional   \n",
       "4       2dc3f9740bda11eba7f7acde48001122      compositional   \n",
       "...                                  ...                ...   \n",
       "167449  56100d300bdc11eba7f7acde48001122      compositional   \n",
       "167450  3df1a97108ad11ebbd83ac1f6bf848b6         comparison   \n",
       "167451  8be4ef3e0bdc11eba7f7acde48001122      compositional   \n",
       "167452  12357df20bdc11eba7f7acde48001122      compositional   \n",
       "167453  613fb15e0bde11eba7f7acde48001122      compositional   \n",
       "\n",
       "                                                 question  \\\n",
       "0       Are director of film Move (1970 Film) and dire...   \n",
       "1       Do both films The Falcon (Film) and Valentin T...   \n",
       "2       Which film whose director is younger, Charge I...   \n",
       "3       What is the date of birth of Mina Gerhardsen's...   \n",
       "4       What nationality is the director of film Weddi...   \n",
       "...                                                   ...   \n",
       "167449  What is the place of birth of the director of ...   \n",
       "167450  Who was born first, Dušan Ninić or Eszter Balint?   \n",
       "167451         When did the director of film Morchha die?   \n",
       "167452  What is the date of birth of the director of f...   \n",
       "167453  Where did the performer of song White Noise (L...   \n",
       "\n",
       "                                                  context  \\\n",
       "0       [[Stuart Rosenberg, [Stuart Rosenberg (August ...   \n",
       "1       [[The Falcon Takes Over, [The Falcon Takes Ove...   \n",
       "2       [[Danger: Diabolik, [Danger:, Diabolik  is a 1...   \n",
       "3       [[Pamela Jain, [Pamela Jain is an Indian playb...   \n",
       "4       [[Weekend in Paradise (1931 film), [Weekend in...   \n",
       "...                                                   ...   \n",
       "167449  [[S. N. Mathur, [S.N. Mathur was the Director ...   \n",
       "167450  [[Tom Dickinson, [Thomas Eastwood Dickinson( 1...   \n",
       "167451  [[Thomas Scott (diver), [Thomas Scott( 1907- d...   \n",
       "167452  [[Peter Levin, [Peter Levin is an American dir...   \n",
       "167453  [[White Noise (Linkin Park song), [White Noise...   \n",
       "\n",
       "                                         supporting_facts  \\\n",
       "0       [[Move (1970 film), 0], [Méditerranée (1963 fi...   \n",
       "1       [[The Falcon (film), 0], [Valentin the Good, 0...   \n",
       "2       [[Charge It to Me, 1], [Danger: Diabolik, 1], ...   \n",
       "3            [[Mina Gerhardsen, 1], [Rune Gerhardsen, 0]]   \n",
       "4       [[Wedding Night in Paradise (1950 film), 0], [...   \n",
       "...                                                   ...   \n",
       "167449  [[Rolling in Money, 0], [Albert Parker (direct...   \n",
       "167450             [[Dušan Ninić, 0], [Eszter Balint, 0]]   \n",
       "167451              [[Morchha, 0], [Ravikant Nagaich, 0]]   \n",
       "167452  [[Double Cross (1951 film), 0], [Riccardo Fred...   \n",
       "167453  [[White Noise (Linkin Park song), 0], [Chester...   \n",
       "\n",
       "                                                evidences  \\\n",
       "0       [[Move (1970 film), director, Stuart Rosenberg...   \n",
       "1       [[The Falcon (film), director, Vatroslav Mimic...   \n",
       "2       [[Charge It to Me, director, Roy William Neill...   \n",
       "3       [[Mina Gerhardsen, father, Rune Gerhardsen], [...   \n",
       "4       [[Wedding Night in Paradise, director, Géza vo...   \n",
       "...                                                   ...   \n",
       "167449  [[Rolling in Money, director, Albert Parker], ...   \n",
       "167450  [[Dušan Ninić, date of birth, September 6, 195...   \n",
       "167451  [[Morchha, director, Ravikant Nagaich], [Ravik...   \n",
       "167452  [[Double Cross, director, Riccardo Freda], [Ri...   \n",
       "167453  [[White Noise, performer, Chester Bennington],...   \n",
       "\n",
       "                      answer  \n",
       "0                         no  \n",
       "1                         no  \n",
       "2           Danger: Diabolik  \n",
       "3               13 June 1946  \n",
       "4                  Hungarian  \n",
       "...                      ...  \n",
       "167449              New York  \n",
       "167450           Dušan Ninić  \n",
       "167451        6 January 1991  \n",
       "167452      24 February 1909  \n",
       "167453  Palos Verdes Estates  \n",
       "\n",
       "[167454 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "truth_df = pandas.read_json('/mnt/data/train.json')\n",
    "truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles: Series([], Name: title, dtype: object)\n",
      "sentences: 12946956    \"The Blinding of Isaac Woodard\" is a song writ...\n",
      "2866679     The club is mentioned in the Motion City Sound...\n",
      "23180998    The Place Where the Black Stars Hang is the fo...\n",
      "9104057     \"My Songs Know What You Did in the Dark (Light...\n",
      "Name: sentences, dtype: object\n"
     ]
    }
   ],
   "source": [
    "query(truth_df.question.iloc[167453])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles: 4353291    White Noise (Linkin Park song)\n",
      "3173141               White Noise (novel)\n",
      "2597077         White Noise (Pvris album)\n",
      "2306136     White Noise (Disclosure song)\n",
      "Name: title, dtype: object\n",
      "sentences: Series([], Name: sentences, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "query('White Noise (Linkin Park song)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: BitGraph currently does not check vertex validity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99999982, 0.99999982])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.V([5013434, 374345]).similarity('emb', [getem('Move (1970 film)')]).toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "def extract(entsList):\n",
    "    words = []\n",
    "    for ents in entsList:\n",
    "        row = []\n",
    "        for ent in ents:\n",
    "            row.append(ent['word'])\n",
    "        words.append(row)\n",
    "    return words\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-large-NER\")\n",
    "\n",
    "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0, aggregation_strategy=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3173141 2597077 2306136 8684283 2196066 1930796   27608 5932958]\n",
      "articles: 3173141              White Noise (novel)\n",
      "2597077        White Noise (Pvris album)\n",
      "2306136    White Noise (Disclosure song)\n",
      "2196066                      Linkin Park\n",
      "1930796                      King's Song\n",
      "27608                          Song Defu\n",
      "5932958                    Song Jong-sun\n",
      "Name: title, dtype: object\n",
      "sentences: 2694436    White Noise\n",
      "Name: sentences, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vids = np.concatenate([\n",
    "    g.V().like('emb', [getem(ent['word'])], 4).toArray()\n",
    "    for ent in ner(truth_df.question.iloc[167453])\n",
    "])\n",
    "\n",
    "print(vids)\n",
    "\n",
    "f = (vids < len(titles))\n",
    "print('articles:', titles.iloc[vids[f].get()])\n",
    "print('sentences:', sentences.iloc[vids[~f].get() - len(titles)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygremlinxx import GraphTraversal\n",
    "__ = lambda : GraphTraversal()\n",
    "\n",
    "# The subgraph step does not work due to nanobind limitations, so use this way instead\n",
    "out = graph.subgraph_coo(\n",
    "    g.V(vids).bothE().dedup()._as('h0').inV().bothE().dedup()._union([__().select('h0'), __().identity()]).dedup().toArray()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "def coo_to_data(coo):\n",
    "    data = Data()\n",
    "    data.edge_index = torch.stack([\n",
    "        torch.as_tensor(coo['dst'].astype('int64'), device='cuda'),\n",
    "        torch.as_tensor(coo['src'].astype('int64'), device='cuda'),\n",
    "    ])\n",
    "    data.x = torch.as_tensor(\n",
    "        g.V(coo['vid']).encode('emb').toArray(),\n",
    "        device='cuda'\n",
    "    ).reshape((-1, 300))\n",
    "    data.batch = torch.zeros((data.x.shape[0],), dtype=torch.int64, device='cuda')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up 'TinyLlama/TinyLlama-1.1B-Chat-v0.1' with configuration: {'revision': 'main', 'max_memory': {0: '9GiB', 1: '45GiB'}, 'low_cpu_mem_usage': True, 'device_map': 'auto', 'torch_dtype': torch.bfloat16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/nlp/llm.py:94: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  self.autocast_context = torch.cuda.amp.autocast(dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GRetriever, GAT\n",
    "from torch_geometric.nn.nlp import LLM\n",
    "\n",
    "llm = LLM(\n",
    "    model_name='TinyLlama/TinyLlama-1.1B-Chat-v0.1',\n",
    "    num_params=1,\n",
    ")\n",
    "\n",
    "gnn = GAT(\n",
    "    in_channels=300,\n",
    "    hidden_channels=256,\n",
    "    out_channels=300,\n",
    "    num_layers=4,\n",
    "    heads=4,\n",
    ")\n",
    "\n",
    "model = GRetriever(llm=llm, gnn=gnn, mlp_out_channels=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 2803], x=[2783, 300], batch=[2783])\n",
      "tensor(3.9530, device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "Data(edge_index=[2, 55], x=[67, 300], batch=[67])\n",
      "tensor(3.8345, device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "Data(edge_index=[2, 33926], x=[33715, 300], batch=[33715])\n",
      "tensor(1.9914, device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ent_fanout = 4 # TODO train this\n",
    "que_fanout = 4 # TODO train this\n",
    "\n",
    "for i in range(3):\n",
    "    question = truth_df.question.iloc[i]\n",
    "    answer = truth_df.answer.iloc[i]\n",
    "    emb_q = getem(question)\n",
    "\n",
    "    vids_q = np.concatenate(\n",
    "        [\n",
    "            g.V().like('emb', [getem(ent['word'])], ent_fanout).toArray()\n",
    "            for ent in ner(question)\n",
    "        ] + [\n",
    "            g.V().like('emb', [emb_q], que_fanout).toArray()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # TODO control hops\n",
    "    # TODO use order step to pick closest to question (like pcst but better?)\n",
    "    out = graph.subgraph_coo(\n",
    "        g.V(vids_q).bothE().dedup()._as('h0').inV().bothE().dedup()._union([__().select('h0'), __().identity()]).dedup().toArray()\n",
    "    )\n",
    "\n",
    "    data = coo_to_data(out)\n",
    "    print(data)\n",
    "\n",
    "    loss = model(\n",
    "        question=[f'question: {question}\\nanswer:'],\n",
    "        x=data.x,\n",
    "        edge_index=data.edge_index,\n",
    "        batch=data.batch,\n",
    "        label=[answer],\n",
    "        edge_attr=None, # edge features\n",
    "        additional_text_context=None # additional context\n",
    "    )\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 33926], x=[33715, 300], batch=[33715])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.V(vids).out().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/bitgraph')\n",
    "sys.path.append('/mnt/gremlin++')\n",
    "from pybitgraph import BitGraph\n",
    "\n",
    "\n",
    "graph = BitGraph(\n",
    "    'uint64',\n",
    "    'uint64',\n",
    "    'DEVICE',\n",
    "    'MANAGED',\n",
    "    'DEVICE',\n",
    ")\n",
    "\n",
    "src = torch.tensor([5, 4, 1, 0, 2, 3, 5, 1, 2, 0], dtype=torch.uint64)\n",
    "dst = torch.tensor([1, 3, 2, 5, 1, 5, 4, 4, 4, 1], dtype=torch.uint64)\n",
    "\n",
    "graph.add_vertices(6)\n",
    "graph.add_edges(src, dst, 'e')\n",
    "\n",
    "g = graph.traversal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.E().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.subgraph_coo(torch.tensor([0, 2, 4], dtype=torch.uint64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.V(2).bothE().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygremlinxx import GraphTraversal\n",
    "__ = lambda : GraphTraversal()\n",
    "\n",
    "g.V([0, ]).bothE().dedup()._as('h0').inV().bothE().dedup()._union([__().select('h0'), __().identity()]).dedup().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
