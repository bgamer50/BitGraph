{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read wiki data\n",
      "0 torch.Size([1, 300])\n",
      "1 torch.Size([1000000, 300])\n",
      "1000001 torch.Size([1000000, 300])\n",
      "2000001 torch.Size([994923, 300])\n",
      "2994924 torch.Size([1, 300])\n",
      "2994925 torch.Size([1000000, 300])\n",
      "3994925 torch.Size([1000000, 300])\n",
      "4994925 torch.Size([994922, 300])\n",
      "5989847 torch.Size([1, 300])\n",
      "5989848 torch.Size([1000000, 300])\n",
      "6989848 torch.Size([1000000, 300])\n",
      "7989848 torch.Size([1000000, 300])\n",
      "8989848 torch.Size([1000000, 300])\n",
      "9989848 torch.Size([1000000, 300])\n",
      "10989848 torch.Size([1000000, 300])\n",
      "11989848 torch.Size([1000000, 300])\n",
      "12989848 torch.Size([1000000, 300])\n",
      "13989848 torch.Size([1000000, 300])\n",
      "14989848 torch.Size([1000000, 300])\n",
      "15989848 torch.Size([1000000, 300])\n",
      "16989848 torch.Size([797125, 300])\n",
      "17786973 torch.Size([1, 300])\n",
      "17786974 torch.Size([1000000, 300])\n",
      "18786974 torch.Size([1000000, 300])\n",
      "19786974 torch.Size([1000000, 300])\n",
      "20786974 torch.Size([1000000, 300])\n",
      "21786974 torch.Size([1000000, 300])\n",
      "22786974 torch.Size([1000000, 300])\n",
      "23786974 torch.Size([1000000, 300])\n",
      "24786974 torch.Size([1000000, 300])\n",
      "25786974 torch.Size([1000000, 300])\n",
      "26786974 torch.Size([1000000, 300])\n",
      "27786974 torch.Size([1000000, 300])\n",
      "28786974 torch.Size([536327, 300])\n",
      "read embeddings into graph\n",
      "constructed graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90803/3562759445.py:160: UserWarning: Word2Vec encoder is for testing/debugging purposes only!\n",
      "  warnings.warn(\"Word2Vec encoder is for testing/debugging purposes only!\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys, os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import rmm\n",
    "from rmm.allocators.torch import rmm_torch_allocator\n",
    "from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "\n",
    "# Initialize shared allocator to prevent fragmentation\n",
    "rmm.reinitialize(devices=0, pool_allocator=False, managed_memory=False)\n",
    "\n",
    "import cupy\n",
    "cupy.cuda.set_allocator(rmm_cupy_allocator)\n",
    "\n",
    "import torch\n",
    "torch.cuda.change_current_allocator(rmm_torch_allocator)\n",
    "\n",
    "import cudf\n",
    "\n",
    "sys.path.append('/mnt/bitgraph')\n",
    "sys.path.append('/mnt/gremlin++')\n",
    "from pybitgraph import BitGraph\n",
    "\n",
    "from preprocess import Sentence_Transformer, Word2Vec_Transformer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def read_wiki_data(fname, skip_empty=True):\n",
    "    df = cudf.read_json('/mnt/para_with_hyperlink.jsonl', lines=True)\n",
    "\n",
    "    mentions = df.mentions.explode()\n",
    "    mentions = mentions[~mentions.struct.field('sent_idx').isna()]\n",
    "    mentions = mentions[~mentions.struct.field('ref_ids').isna()]\n",
    "\n",
    "    slens = df.sentences.list.len().astype('int64')\n",
    "    slens[(slens==0)] = 1\n",
    "\n",
    "    df['sentence_offsets'] = cupy.concatenate([\n",
    "        cupy.array([0]),\n",
    "        slens.cumsum().values[:-1]\n",
    "    ])\n",
    "\n",
    "    mix = torch.as_tensor(\n",
    "        mentions.struct.field('ref_ids').list.get(0).astype('int64').values,\n",
    "        device='cuda'\n",
    "    )\n",
    "    ids = torch.as_tensor(df.id.astype('int64').values, device='cuda')\n",
    "    vals, inds = torch.sort(ids)\n",
    "\n",
    "    destinations_m = inds[torch.searchsorted(vals, mix)]\n",
    "    sources_m = torch.as_tensor(\n",
    "        mentions.struct.field('sent_idx').values + df.sentence_offsets[mentions.index].values + len(df),\n",
    "        device='cuda'\n",
    "    )\n",
    "\n",
    "    if skip_empty:\n",
    "        # Does not add vertices/edges for vertices with no embedding\n",
    "        f = destinations_m < len(df)\n",
    "        destinations_m = destinations_m[f]\n",
    "        sources_m = sources_m[f]\n",
    "        del f\n",
    "\n",
    "    eim = torch.stack([\n",
    "        torch.as_tensor(sources_m, device='cuda'),\n",
    "        torch.as_tensor(destinations_m, device='cuda'),\n",
    "    ])\n",
    "\n",
    "    sentences = df.sentences.explode().reset_index().rename({\"index\": 'article'},axis=1)\n",
    "\n",
    "    sources_s = sentences.index.values + len(df)\n",
    "    destinations_s = sentences.article.values\n",
    "    eis = torch.stack([\n",
    "        torch.as_tensor(sources_s, device='cuda'),\n",
    "        torch.as_tensor(destinations_s, device='cuda'),\n",
    "    ])\n",
    "\n",
    "    eix = torch.concatenate([eim,eis],axis=1)\n",
    "    del eis\n",
    "    del eim\n",
    "\n",
    "    return eix, df.title.to_pandas(), sentences.sentences.to_pandas()\n",
    "\n",
    "\n",
    "def read_embeddings(graph, directory, td):\n",
    "    ex = re.compile(r'part_([0-9]+)\\_([0-9]+).pt')\n",
    "    def fname_to_key(s):\n",
    "        m = ex.match(s)\n",
    "        return int(m[1]), int(m[2])\n",
    "\n",
    "    ix = 0\n",
    "\n",
    "    for emb_type in ['titles', 'sentences']:\n",
    "        path = os.path.join(directory, emb_type)\n",
    "        files = os.listdir(path)\n",
    "\n",
    "        files = sorted(files, key=fname_to_key)\n",
    "        for f in files:\n",
    "            e = torch.load(os.path.join(path, f), weights_only=True, map_location='cuda').reshape((-1, td))\n",
    "\n",
    "            print(ix, e.shape)\n",
    "            graph.set_vertex_embeddings('emb', ix, ix + e.shape[0] - 1, e)\n",
    "            \n",
    "            ix += e.shape[0]\n",
    "            del e\n",
    "\n",
    "\n",
    "def getem_roberta(model, tokenizer, text):\n",
    "    t = tokenizer(text, return_tensors='pt')\n",
    "    while t.input_ids.shape[1] > 512:\n",
    "        a = a[:-10]\n",
    "        t = tokenizer(a, return_tensors='pt')\n",
    "    return model(t.input_ids, t.attention_mask)\n",
    "\n",
    "\n",
    "def getem_w2v(model, text):\n",
    "    return model(text)\n",
    "\n",
    "\n",
    "args = {\n",
    "    'skip_empty_vertices': True,\n",
    "    'property_storage': 'managed',\n",
    "    'fname': '/mnt/para_with_hyperlink.jsonl',\n",
    "    'embeddings_dir': '/mnt/bitgraph/data/rag/w2v/',\n",
    "    'embedding_type': 'w2v',\n",
    "    'w2v_path': '/mnt/GoogleNews-vectors-negative300.bin.gz',\n",
    "}\n",
    "\n",
    "eix, titles, sentences = read_wiki_data(\n",
    "    args['fname'],\n",
    "    args['skip_empty_vertices']\n",
    ")\n",
    "print('read wiki data')\n",
    "\n",
    "graph = BitGraph(\n",
    "    'int64',\n",
    "    'int64',\n",
    "    'DEVICE',\n",
    "    'DEVICE',\n",
    "    args['property_storage'].upper(),\n",
    ")\n",
    "\n",
    "graph.add_vertices(eix.max() + 1)\n",
    "graph.add_edges(eix[0], eix[1], 'link')\n",
    "\n",
    "read_embeddings(\n",
    "    graph,\n",
    "    args['embeddings_dir'],\n",
    "    td=300 if args['embedding_type'] == 'w2v' else 1024,\n",
    ")    \n",
    "print('read embeddings into graph')\n",
    "\n",
    "g = graph.traversal()\n",
    "print('constructed graph')\n",
    "\n",
    "if args['embedding_type'] == 'w2v':\n",
    "    import gensim\n",
    "    warnings.warn(\"Word2Vec encoder is for testing/debugging purposes only!\")\n",
    "    module = Word2Vec_Transformer(\n",
    "        gensim.models.KeyedVectors.load_word2vec_format(args['w2v_path'], binary=True),\n",
    "        dim=300,\n",
    "    )\n",
    "    getem = lambda t : getem_w2v(module, t)\n",
    "elif args['embedding_type'] == 'roberta':\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/all-roberta-large-v1')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-roberta-large-v1')\n",
    "    \n",
    "    mod = Sentence_Transformer(model).cuda()\n",
    "    import torch._dynamo\n",
    "    torch._dynamo.reset()\n",
    "\n",
    "    module = torch.compile(mod, fullgraph=True)\n",
    "    getem = lambda t : getem_roberta(module, tokenizer, t)\n",
    "else:\n",
    "    raise ValueError(\"Expected 'w2v' or 'roberta' for embedding type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(search_query, lim=4):\n",
    "    qe = getem(search_query)\n",
    "    vids = g.V().like('emb', [qe], lim).toArray()\n",
    "\n",
    "    f = vids < len(titles)\n",
    "    article_ids = vids[f]\n",
    "    sentence_ids = vids[~f] - len(titles)\n",
    "\n",
    "    print('articles:', titles.iloc[article_ids.get()])\n",
    "    print('sentences:', sentences.iloc[sentence_ids.get()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "truth_df = pandas.read_json('/mnt/data/train.json')\n",
    "truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df.question.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[z[0] for z in truth_df.supporting_facts.iloc[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\n'.join([' '.join(z[1]) for z in truth_df.context.iloc[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(truth_df.question.iloc[167453])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2902052])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.V().like('emb', [getem(\"Miley Cyrus\")], 1).toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([327], dtype=uint64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.V().like('emb', [getem(\"Miley Cyrus\")], 1)._in().count().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600544    \"Pumpin' Up the Party\" is a pop song by Americ...\n",
       "7600545    She is performing as Hannah Montana – the alte...\n",
       "7600546    The song was released to Radio Disney as promo...\n",
       "7600547      The song has teen pop and dance-pop influences.\n",
       "7600548    In the United States, the song peaked at numbe...\n",
       "7600549    Its appearance on the \"Billboard\" Hot 100 made...\n",
       "7600550    A music video for \"Pumpin' Up the Party\" was t...\n",
       "7600551    Cyrus, dressed as Hannah Montana, performed th...\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.iloc[g.V().like('emb', [getem(\"Pumpin ' Up The Party\")], 1)._in().toArray().get() - len(titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miley (surname)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles.iloc[2902052]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1954484, 4998348])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.V().like('emb', [getem(\"Pumpin ' Up The Party\")], 2).toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  946208,  3130776,  5072346,  6709252,  8821095, 14736735,\n",
       "       16161698, 18491732, 29522486, 29522487, 29522488, 29522489,\n",
       "       29522490, 29522491, 29522492, 29522493, 41512249, 41512250])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = g.V().like('emb', [getem(\"Pumpin ' Up The Party\")], 2).inE().order().toArray().get()\n",
    "v\n",
    "#titles.iloc[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.V([5013434, 374345]).similarity('emb', [getem('Move (1970 film)')]).toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "def extract(entsList):\n",
    "    words = []\n",
    "    for ents in entsList:\n",
    "        row = []\n",
    "        for ent in ents:\n",
    "            row.append(ent['word'])\n",
    "        words.append(row)\n",
    "    return words\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-large-NER\")\n",
    "\n",
    "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0, aggregation_strategy=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vids = np.concatenate([\n",
    "    g.V().like('emb', [getem(ent['word'])], 4).toArray()\n",
    "    for ent in ner(truth_df.question.iloc[167453])\n",
    "])\n",
    "\n",
    "print(vids)\n",
    "\n",
    "f = (vids < len(titles))\n",
    "print('articles:', titles.iloc[vids[f].get()])\n",
    "print('sentences:', sentences.iloc[vids[~f].get() - len(titles)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygremlinxx import GraphTraversal\n",
    "__ = lambda : GraphTraversal()\n",
    "\n",
    "# The subgraph step does not work due to nanobind limitations, so use this way instead\n",
    "out = graph.subgraph_coo(\n",
    "    g.V(vids).bothE().dedup()._as('h0').inV().bothE().dedup()._union([__().select('h0'), __().identity()]).dedup().toArray()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "def coo_to_data(coo):\n",
    "    data = Data()\n",
    "    data.edge_index = torch.stack([\n",
    "        torch.as_tensor(coo['dst'].astype('int64'), device='cuda'),\n",
    "        torch.as_tensor(coo['src'].astype('int64'), device='cuda'),\n",
    "    ])\n",
    "    data.x = torch.as_tensor(\n",
    "        g.V(coo['vid']).encode('emb').toArray(),\n",
    "        device='cuda'\n",
    "    ).reshape((-1, 300))\n",
    "    data.batch = torch.zeros((data.x.shape[0],), dtype=torch.int64, device='cuda')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GRetriever, GAT\n",
    "from torch_geometric.nn.nlp import LLM\n",
    "\n",
    "llm = LLM(\n",
    "    model_name='TinyLlama/TinyLlama-1.1B-Chat-v0.1',\n",
    "    num_params=1,\n",
    ")\n",
    "\n",
    "gnn = GAT(\n",
    "    in_channels=300,\n",
    "    hidden_channels=256,\n",
    "    out_channels=300,\n",
    "    num_layers=4,\n",
    "    heads=4,\n",
    ")\n",
    "\n",
    "model = GRetriever(llm=llm, gnn=gnn, mlp_out_channels=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_match_limit = 4\n",
    "que_match_limit = 4\n",
    "\n",
    "out_limit_h0 = 4\n",
    "out_limit_h1 = 4\n",
    "in_limit_h0 = 4\n",
    "in_limit_h1 = 4\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "for i in range(3):\n",
    "    question = truth_df.question.iloc[i]\n",
    "    answer = truth_df.answer.iloc[i]\n",
    "    emb_q = getem(question)\n",
    "\n",
    "    vids_q = np.concatenate(\n",
    "        [\n",
    "            g.V().like('emb', [getem(ent['word'])], ent_match_limit).toArray()\n",
    "            for ent in ner(question)\n",
    "        ] + [\n",
    "            g.V().like('emb', [emb_q], que_match_limit).toArray()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # TODO control hops\n",
    "    start_time = perf_counter()\n",
    "    eids = g.V(vids_q)._union([\n",
    "        __().outE().order().by(__().inV().similarity('emb', [emb_q])).limit(4)._as('h0').inV(),\n",
    "        __().inE().order().by(__().outV().similarity('emb', [emb_q])).limit(4)._as('h0').outV(),\n",
    "    ])._union([\n",
    "        __().outE().order().by(__().inV().similarity('emb', [emb_q])).limit(4)._as('h1').inV(),\n",
    "        __().inE().order().by(__().outV().similarity('emb', [emb_q])).limit(4)._as('h1').outV(),\n",
    "    ])._union([__().select('h0'), __().select('h1')]).dedup().toArray()\n",
    "    end_time = perf_counter()\n",
    "\n",
    "    print('query time:', end_time - start_time)\n",
    "\n",
    "    out = graph.subgraph_coo(\n",
    "        eids\n",
    "    )\n",
    "\n",
    "    data = coo_to_data(out)\n",
    "    print(data)\n",
    "\n",
    "    loss = model(\n",
    "        question=[f'question: {question}\\nanswer:'],\n",
    "        x=data.x,\n",
    "        edge_index=data.edge_index,\n",
    "        batch=data.batch,\n",
    "        label=[answer],\n",
    "        edge_attr=None, # edge features\n",
    "        additional_text_context=None # additional context\n",
    "    )\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.V(vids).out().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/bitgraph')\n",
    "sys.path.append('/mnt/gremlin++')\n",
    "from pybitgraph import BitGraph\n",
    "\n",
    "\n",
    "graph = BitGraph(\n",
    "    'uint64',\n",
    "    'uint64',\n",
    "    'DEVICE',\n",
    "    'MANAGED',\n",
    "    'DEVICE',\n",
    ")\n",
    "\n",
    "src = torch.tensor([5, 4, 1, 0, 2, 3, 5, 1, 2, 0], dtype=torch.uint64)\n",
    "dst = torch.tensor([1, 3, 2, 5, 1, 5, 4, 4, 4, 1], dtype=torch.uint64)\n",
    "\n",
    "graph.add_vertices(6)\n",
    "graph.add_edges(src, dst, 'e')\n",
    "\n",
    "g = graph.traversal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.E().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.subgraph_coo(torch.tensor([0, 2, 4], dtype=torch.uint64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.V(2).bothE().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygremlinxx import GraphTraversal\n",
    "__ = lambda : GraphTraversal()\n",
    "\n",
    "g.V([0, ]).bothE().dedup()._as('h0').inV().bothE().dedup()._union([__().select('h0'), __().identity()]).dedup().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "df = cudf.read_json('/mnt/para_with_hyperlink.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 181012, 5324480, 3286068,  ..., 2423755, 5409000, 2196530],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "mentions = df.mentions.explode()\n",
    "mentions = mentions[~mentions.struct.field('sent_idx').isna()]\n",
    "mentions = mentions[~mentions.struct.field('ref_ids').isna()]\n",
    "\n",
    "mix = torch.as_tensor(\n",
    "    mentions.struct.field('ref_ids').list.get(0).astype('int64').values,\n",
    "    device='cuda'\n",
    ")\n",
    "ids = torch.as_tensor(df.id.astype('int64').values, device='cuda')\n",
    "vals, inds = torch.sort(ids)\n",
    "\n",
    "\n",
    "destinations_m = inds[torch.searchsorted(vals, mix)]\n",
    "destinations_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>sentences</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentence_offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17888798</td>\n",
       "      <td>The Circle (Wipers album)</td>\n",
       "      <td>[The Circle is the sixth studio album by punk ...</td>\n",
       "      <td>[{'id': 0, 'start': 40, 'end': 49, 'ref_url': ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17888807</td>\n",
       "      <td>Urgand</td>\n",
       "      <td>[Urgand is a village in Badakhshan Province in...</td>\n",
       "      <td>[{'id': 0, 'start': 12, 'end': 19, 'ref_url': ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17888822</td>\n",
       "      <td>Urup, Afghanistan</td>\n",
       "      <td>[Urup is a village in Badakhshan Province in n...</td>\n",
       "      <td>[{'id': 0, 'start': 10, 'end': 17, 'ref_url': ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17888850</td>\n",
       "      <td>WMIA (AM)</td>\n",
       "      <td>[\"For the Miami, Florida radio station, see WM...</td>\n",
       "      <td>[{'id': 0, 'start': 9, 'end': 23, 'ref_url': '...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17888858</td>\n",
       "      <td>Guido of Acqui</td>\n",
       "      <td>[Saint Guido of Acqui( also Wido)( c. 1004 – 1...</td>\n",
       "      <td>[{'id': 0, 'start': 62, 'end': 77, 'ref_url': ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989842</th>\n",
       "      <td>12347579</td>\n",
       "      <td>Hebeclinium</td>\n",
       "      <td>[Hebeclinium is a genus of flowering plant in ...</td>\n",
       "      <td>[{'id': 0, 'start': 26, 'end': 41, 'ref_url': ...</td>\n",
       "      <td>23333440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989843</th>\n",
       "      <td>12347585</td>\n",
       "      <td>Hebeclinium recreense</td>\n",
       "      <td>[Hebeclinium recreense is a species of floweri...</td>\n",
       "      <td>[{'id': 0, 'start': 38, 'end': 53, 'ref_url': ...</td>\n",
       "      <td>23333441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989844</th>\n",
       "      <td>12347593</td>\n",
       "      <td>Helichrysum aciculare</td>\n",
       "      <td>[Helichrysum aciculare is a species of floweri...</td>\n",
       "      <td>[{'id': 0, 'start': 38, 'end': 53, 'ref_url': ...</td>\n",
       "      <td>23333445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989845</th>\n",
       "      <td>12347598</td>\n",
       "      <td>Helichrysum arachnoides</td>\n",
       "      <td>[Helichrysum arachnoides is a species of flowe...</td>\n",
       "      <td>[{'id': 0, 'start': 40, 'end': 55, 'ref_url': ...</td>\n",
       "      <td>23333448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989846</th>\n",
       "      <td>12347604</td>\n",
       "      <td>Helichrysum balfourii</td>\n",
       "      <td>[Helichrysum balfourii is a species of floweri...</td>\n",
       "      <td>[{'id': 0, 'start': 38, 'end': 53, 'ref_url': ...</td>\n",
       "      <td>23333451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5989847 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                      title  \\\n",
       "0        17888798  The Circle (Wipers album)   \n",
       "1        17888807                     Urgand   \n",
       "2        17888822          Urup, Afghanistan   \n",
       "3        17888850                  WMIA (AM)   \n",
       "4        17888858             Guido of Acqui   \n",
       "...           ...                        ...   \n",
       "5989842  12347579                Hebeclinium   \n",
       "5989843  12347585      Hebeclinium recreense   \n",
       "5989844  12347593      Helichrysum aciculare   \n",
       "5989845  12347598    Helichrysum arachnoides   \n",
       "5989846  12347604      Helichrysum balfourii   \n",
       "\n",
       "                                                 sentences  \\\n",
       "0        [The Circle is the sixth studio album by punk ...   \n",
       "1        [Urgand is a village in Badakhshan Province in...   \n",
       "2        [Urup is a village in Badakhshan Province in n...   \n",
       "3        [\"For the Miami, Florida radio station, see WM...   \n",
       "4        [Saint Guido of Acqui( also Wido)( c. 1004 – 1...   \n",
       "...                                                    ...   \n",
       "5989842  [Hebeclinium is a genus of flowering plant in ...   \n",
       "5989843  [Hebeclinium recreense is a species of floweri...   \n",
       "5989844  [Helichrysum aciculare is a species of floweri...   \n",
       "5989845  [Helichrysum arachnoides is a species of flowe...   \n",
       "5989846  [Helichrysum balfourii is a species of floweri...   \n",
       "\n",
       "                                                  mentions  sentence_offsets  \n",
       "0        [{'id': 0, 'start': 40, 'end': 49, 'ref_url': ...                 0  \n",
       "1        [{'id': 0, 'start': 12, 'end': 19, 'ref_url': ...                 3  \n",
       "2        [{'id': 0, 'start': 10, 'end': 17, 'ref_url': ...                 4  \n",
       "3        [{'id': 0, 'start': 9, 'end': 23, 'ref_url': '...                 5  \n",
       "4        [{'id': 0, 'start': 62, 'end': 77, 'ref_url': ...                10  \n",
       "...                                                    ...               ...  \n",
       "5989842  [{'id': 0, 'start': 26, 'end': 41, 'ref_url': ...          23333440  \n",
       "5989843  [{'id': 0, 'start': 38, 'end': 53, 'ref_url': ...          23333441  \n",
       "5989844  [{'id': 0, 'start': 38, 'end': 53, 'ref_url': ...          23333445  \n",
       "5989845  [{'id': 0, 'start': 40, 'end': 55, 'ref_url': ...          23333448  \n",
       "5989846  [{'id': 0, 'start': 38, 'end': 53, 'ref_url': ...          23333451  \n",
       "\n",
       "[5989847 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cupy\n",
    "\n",
    "slens = df.sentences.list.len().astype('int64')\n",
    "slens[(slens==0)] = 1\n",
    "\n",
    "df['sentence_offsets'] = cupy.concatenate([\n",
    "    cupy.array([0]),\n",
    "    slens.cumsum().values[:-1]\n",
    "])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5989847,  5989847,  5989847,  ..., 29323299, 29323300, 29323300],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.as_tensor(\n",
    "    mentions.struct.field('sent_idx').values + df.sentence_offsets[mentions.index].values,\n",
    "    device='cuda'\n",
    ") + len(df)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(src[(destinations_m == 4111782)] == 13590393).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Circle is the sixth studio album by punk r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The album received positive reviews.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\"The Rough Guide to Rock\" wrote that \"jazzy di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Urgand is a village in Badakhshan Province in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Urup is a village in Badakhshan Province in no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23333449</th>\n",
       "      <td>5989845</td>\n",
       "      <td>It is found only in Yemen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23333450</th>\n",
       "      <td>5989845</td>\n",
       "      <td>Its natural habitat is subtropical or tropical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23333451</th>\n",
       "      <td>5989846</td>\n",
       "      <td>Helichrysum balfourii is a species of flowerin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23333452</th>\n",
       "      <td>5989846</td>\n",
       "      <td>It is found only in Yemen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23333453</th>\n",
       "      <td>5989846</td>\n",
       "      <td>Its natural habitat is subtropical or tropical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23333454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          article                                          sentences\n",
       "0               0  The Circle is the sixth studio album by punk r...\n",
       "1               0               The album received positive reviews.\n",
       "2               0  \"The Rough Guide to Rock\" wrote that \"jazzy di...\n",
       "3               1  Urgand is a village in Badakhshan Province in ...\n",
       "4               2  Urup is a village in Badakhshan Province in no...\n",
       "...           ...                                                ...\n",
       "23333449  5989845                         It is found only in Yemen.\n",
       "23333450  5989845  Its natural habitat is subtropical or tropical...\n",
       "23333451  5989846  Helichrysum balfourii is a species of flowerin...\n",
       "23333452  5989846                         It is found only in Yemen.\n",
       "23333453  5989846  Its natural habitat is subtropical or tropical...\n",
       "\n",
       "[23333454 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = df.sentences.explode().reset_index().rename({\"index\": 'article'},axis=1)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.sentences.explode().reset_index().rename({\"index\": 'article'},axis=1)\n",
    "sentences.dropna(inplace=True)\n",
    "sentences.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations_s = sentences.index.values + len(df)\n",
    "sources_s = sentences.article.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations_s[sources_s==1954484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.iloc[13560798-len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[sentences.article==1954484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7600544+len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions[-5:].struct.field('ref_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions[-5:].struct.field('ref_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.iloc[src[-5:]].sentences.values_host.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = {\"question_vertex_match_limit\": 1, \"hop_1_outgoing_limit\": 8, \"hop_1_incoming_limit\": 8, \"hop_0_outgoing_limit\": 2, \"hop_0_incoming_limit\": 2, \"entity_vertex_match_limit\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"What is the date of birth of the director of film Rathimanmadhan?\"\n",
    "#question = \"What is the place of birth of the director of film Discord (Film)?\"\n",
    "#question = \"Did the movies Torkaman (Film) and Shameless (2008 Film), originate from the same country?\"\n",
    "question = \"Do both directors of films The Big Bang (1989 Film) and Tender Fictions share the same nationality?\"\n",
    "\n",
    "ents = ner(question)\n",
    "emb_q = getem(question)\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(vids):\n",
    "    f = (vids < len(titles))\n",
    "    print('articles:', titles.iloc[vids[f].get()])\n",
    "    print('sentences:', sentences.iloc[vids[~f].get() - len(titles)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.V().like('emb', [emb_q], qp['question_vertex_match_limit']).toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getem('Shameless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vids_q = cupy.concatenate(\n",
    "    [\n",
    "        g.V().like('emb', [getem(ent['word'])], qp['entity_vertex_match_limit']).toArray()\n",
    "        for ent in ents\n",
    "    ] + [\n",
    "        g.V().like('emb', [emb_q], qp['question_vertex_match_limit']).toArray()\n",
    "    ]\n",
    ")\n",
    "decode(vids_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp['question_vertex_match_limit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = g.V().like('emb', [getem('Shameless')], 4).toArray()\n",
    "decode(vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles.iloc[5956065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.iloc[vids_q.get() - len(titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygremlinxx import GraphTraversal\n",
    "__ = lambda : GraphTraversal()\n",
    "\n",
    "vids = g.V(vids_q)._union([\n",
    "    __().out().order().by(__().similarity('emb', [emb_q])).limit(qp['hop_0_outgoing_limit'])._as('h0'),\n",
    "    __()._in().order().by(__().similarity('emb', [emb_q])).limit(qp['hop_0_incoming_limit'])._as('h0'),\n",
    "])._union([\n",
    "    __().out().order().by(__().similarity('emb', [emb_q])).limit(qp['hop_1_outgoing_limit'])._as('h1'),\n",
    "    __()._in().order().by(__().similarity('emb', [emb_q])).limit(qp['hop_1_incoming_limit'])._as('h1'),\n",
    "])._union([__().select('h0'), __().select('h1')]).dedup().toArray()\n",
    "\n",
    "decode(vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.read_json('/mnt/data/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>evidences</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13f5ad2c088c11ebbd6fac1f6bf848b6</td>\n",
       "      <td>bridge_comparison</td>\n",
       "      <td>Are director of film Move (1970 Film) and dire...</td>\n",
       "      <td>[[Stuart Rosenberg, [Stuart Rosenberg (August ...</td>\n",
       "      <td>[[Move (1970 film), 0], [Méditerranée (1963 fi...</td>\n",
       "      <td>[[Move (1970 film), director, Stuart Rosenberg...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3057c6c4086111ebbd5dac1f6bf848b6</td>\n",
       "      <td>bridge_comparison</td>\n",
       "      <td>Do both films The Falcon (Film) and Valentin T...</td>\n",
       "      <td>[[The Falcon Takes Over, [The Falcon Takes Ove...</td>\n",
       "      <td>[[The Falcon (film), 0], [Valentin the Good, 0...</td>\n",
       "      <td>[[The Falcon (film), director, Vatroslav Mimic...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89bc944808a111ebbd79ac1f6bf848b6</td>\n",
       "      <td>bridge_comparison</td>\n",
       "      <td>Which film whose director is younger, Charge I...</td>\n",
       "      <td>[[Danger: Diabolik, [Danger:, Diabolik  is a 1...</td>\n",
       "      <td>[[Charge It to Me, 1], [Danger: Diabolik, 1], ...</td>\n",
       "      <td>[[Charge It to Me, director, Roy William Neill...</td>\n",
       "      <td>Danger: Diabolik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633f80660bdd11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What is the date of birth of Mina Gerhardsen's...</td>\n",
       "      <td>[[Pamela Jain, [Pamela Jain is an Indian playb...</td>\n",
       "      <td>[[Mina Gerhardsen, 1], [Rune Gerhardsen, 0]]</td>\n",
       "      <td>[[Mina Gerhardsen, father, Rune Gerhardsen], [...</td>\n",
       "      <td>13 June 1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2dc3f9740bda11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What nationality is the director of film Weddi...</td>\n",
       "      <td>[[Weekend in Paradise (1931 film), [Weekend in...</td>\n",
       "      <td>[[Wedding Night in Paradise (1950 film), 0], [...</td>\n",
       "      <td>[[Wedding Night in Paradise, director, Géza vo...</td>\n",
       "      <td>Hungarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167449</th>\n",
       "      <td>56100d300bdc11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What is the place of birth of the director of ...</td>\n",
       "      <td>[[S. N. Mathur, [S.N. Mathur was the Director ...</td>\n",
       "      <td>[[Rolling in Money, 0], [Albert Parker (direct...</td>\n",
       "      <td>[[Rolling in Money, director, Albert Parker], ...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167450</th>\n",
       "      <td>3df1a97108ad11ebbd83ac1f6bf848b6</td>\n",
       "      <td>comparison</td>\n",
       "      <td>Who was born first, Dušan Ninić or Eszter Balint?</td>\n",
       "      <td>[[Tom Dickinson, [Thomas Eastwood Dickinson( 1...</td>\n",
       "      <td>[[Dušan Ninić, 0], [Eszter Balint, 0]]</td>\n",
       "      <td>[[Dušan Ninić, date of birth, September 6, 195...</td>\n",
       "      <td>Dušan Ninić</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167451</th>\n",
       "      <td>8be4ef3e0bdc11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>When did the director of film Morchha die?</td>\n",
       "      <td>[[Thomas Scott (diver), [Thomas Scott( 1907- d...</td>\n",
       "      <td>[[Morchha, 0], [Ravikant Nagaich, 0]]</td>\n",
       "      <td>[[Morchha, director, Ravikant Nagaich], [Ravik...</td>\n",
       "      <td>6 January 1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167452</th>\n",
       "      <td>12357df20bdc11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>What is the date of birth of the director of f...</td>\n",
       "      <td>[[Peter Levin, [Peter Levin is an American dir...</td>\n",
       "      <td>[[Double Cross (1951 film), 0], [Riccardo Fred...</td>\n",
       "      <td>[[Double Cross, director, Riccardo Freda], [Ri...</td>\n",
       "      <td>24 February 1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167453</th>\n",
       "      <td>613fb15e0bde11eba7f7acde48001122</td>\n",
       "      <td>compositional</td>\n",
       "      <td>Where did the performer of song White Noise (L...</td>\n",
       "      <td>[[White Noise (Linkin Park song), [White Noise...</td>\n",
       "      <td>[[White Noise (Linkin Park song), 0], [Chester...</td>\n",
       "      <td>[[White Noise, performer, Chester Bennington],...</td>\n",
       "      <td>Palos Verdes Estates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167454 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     _id               type  \\\n",
       "0       13f5ad2c088c11ebbd6fac1f6bf848b6  bridge_comparison   \n",
       "1       3057c6c4086111ebbd5dac1f6bf848b6  bridge_comparison   \n",
       "2       89bc944808a111ebbd79ac1f6bf848b6  bridge_comparison   \n",
       "3       633f80660bdd11eba7f7acde48001122      compositional   \n",
       "4       2dc3f9740bda11eba7f7acde48001122      compositional   \n",
       "...                                  ...                ...   \n",
       "167449  56100d300bdc11eba7f7acde48001122      compositional   \n",
       "167450  3df1a97108ad11ebbd83ac1f6bf848b6         comparison   \n",
       "167451  8be4ef3e0bdc11eba7f7acde48001122      compositional   \n",
       "167452  12357df20bdc11eba7f7acde48001122      compositional   \n",
       "167453  613fb15e0bde11eba7f7acde48001122      compositional   \n",
       "\n",
       "                                                 question  \\\n",
       "0       Are director of film Move (1970 Film) and dire...   \n",
       "1       Do both films The Falcon (Film) and Valentin T...   \n",
       "2       Which film whose director is younger, Charge I...   \n",
       "3       What is the date of birth of Mina Gerhardsen's...   \n",
       "4       What nationality is the director of film Weddi...   \n",
       "...                                                   ...   \n",
       "167449  What is the place of birth of the director of ...   \n",
       "167450  Who was born first, Dušan Ninić or Eszter Balint?   \n",
       "167451         When did the director of film Morchha die?   \n",
       "167452  What is the date of birth of the director of f...   \n",
       "167453  Where did the performer of song White Noise (L...   \n",
       "\n",
       "                                                  context  \\\n",
       "0       [[Stuart Rosenberg, [Stuart Rosenberg (August ...   \n",
       "1       [[The Falcon Takes Over, [The Falcon Takes Ove...   \n",
       "2       [[Danger: Diabolik, [Danger:, Diabolik  is a 1...   \n",
       "3       [[Pamela Jain, [Pamela Jain is an Indian playb...   \n",
       "4       [[Weekend in Paradise (1931 film), [Weekend in...   \n",
       "...                                                   ...   \n",
       "167449  [[S. N. Mathur, [S.N. Mathur was the Director ...   \n",
       "167450  [[Tom Dickinson, [Thomas Eastwood Dickinson( 1...   \n",
       "167451  [[Thomas Scott (diver), [Thomas Scott( 1907- d...   \n",
       "167452  [[Peter Levin, [Peter Levin is an American dir...   \n",
       "167453  [[White Noise (Linkin Park song), [White Noise...   \n",
       "\n",
       "                                         supporting_facts  \\\n",
       "0       [[Move (1970 film), 0], [Méditerranée (1963 fi...   \n",
       "1       [[The Falcon (film), 0], [Valentin the Good, 0...   \n",
       "2       [[Charge It to Me, 1], [Danger: Diabolik, 1], ...   \n",
       "3            [[Mina Gerhardsen, 1], [Rune Gerhardsen, 0]]   \n",
       "4       [[Wedding Night in Paradise (1950 film), 0], [...   \n",
       "...                                                   ...   \n",
       "167449  [[Rolling in Money, 0], [Albert Parker (direct...   \n",
       "167450             [[Dušan Ninić, 0], [Eszter Balint, 0]]   \n",
       "167451              [[Morchha, 0], [Ravikant Nagaich, 0]]   \n",
       "167452  [[Double Cross (1951 film), 0], [Riccardo Fred...   \n",
       "167453  [[White Noise (Linkin Park song), 0], [Chester...   \n",
       "\n",
       "                                                evidences  \\\n",
       "0       [[Move (1970 film), director, Stuart Rosenberg...   \n",
       "1       [[The Falcon (film), director, Vatroslav Mimic...   \n",
       "2       [[Charge It to Me, director, Roy William Neill...   \n",
       "3       [[Mina Gerhardsen, father, Rune Gerhardsen], [...   \n",
       "4       [[Wedding Night in Paradise, director, Géza vo...   \n",
       "...                                                   ...   \n",
       "167449  [[Rolling in Money, director, Albert Parker], ...   \n",
       "167450  [[Dušan Ninić, date of birth, September 6, 195...   \n",
       "167451  [[Morchha, director, Ravikant Nagaich], [Ravik...   \n",
       "167452  [[Double Cross, director, Riccardo Freda], [Ri...   \n",
       "167453  [[White Noise, performer, Chester Bennington],...   \n",
       "\n",
       "                      answer  \n",
       "0                         no  \n",
       "1                         no  \n",
       "2           Danger: Diabolik  \n",
       "3               13 June 1946  \n",
       "4                  Hungarian  \n",
       "...                      ...  \n",
       "167449              New York  \n",
       "167450           Dušan Ninić  \n",
       "167451        6 January 1991  \n",
       "167452      24 February 1909  \n",
       "167453  Palos Verdes Estates  \n",
       "\n",
       "[167454 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which film has the director who died later, Aaranya Kandam or One Hundred Nails?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.question[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
